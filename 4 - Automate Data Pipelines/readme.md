# Project 4 - Automate Data Pipelines with Airflow

As in the previous project this project 4 deals with the music-streaming-dataset of the startup *Sparkify*. In order schedule and monitor data pipelines **Apache Airflow** is used to orchestrate an ETL extracting data from **S3** and loading it into a **Redshift** database.

---

## Data Pipeline with Airflow

s

s 

## Redshift Data Model

The final Redshift star schema consists of 1 fact table and 4 dimension tables.

![Redshift Data Model]([https://github.com/horony/udacity-nanodegree-data-engineering/blob/main/4%20-%20Automate%20Data%20Pipelines/images/airflow_data_model.PNG])

